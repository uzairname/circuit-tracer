{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37d26ac",
   "metadata": {},
   "source": [
    "# Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9abfd03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074b75c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from circuit_tracer import ReplacementModel, attribute\n",
    "from circuit_tracer.utils import create_graph_files\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'google/gemma-2-2b'\n",
    "transcoder_name = \"gemma\"\n",
    "model = ReplacementModel.from_pretrained(model_name, transcoder_name, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b5fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir = 'graphs'\n",
    "graph_name = 'war.pt'\n",
    "graph_dir = Path(graph_dir)\n",
    "graph_dir.mkdir(exist_ok=True)\n",
    "graph_path = graph_dir / graph_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01922ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 0: Precomputing activations and vectors\n",
      "Precomputation completed in 0.19s\n",
      "Found 12392 active features\n",
      "Phase 1: Running forward pass\n",
      "Forward pass completed in 1.13s\n",
      "Phase 2: Building input vectors\n",
      "Selected 3 logits with cumulative probability 0.9766\n",
      "Will include 8192 of 12392 feature nodes\n",
      "Input vectors built in 0.75s\n",
      "Phase 3: Computing logit attributions\n",
      "Logit attributions completed in 0.30s\n",
      "Phase 4: Computing feature attributions\n",
      "Feature influence computation: 100%|██████████| 8192/8192 [00:08<00:00, 942.68it/s] \n",
      "Feature attributions completed in 8.69s\n",
      "Attribution completed in 11.21s\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The war lasted from the year 1711 to 17\"  # What you want to get the graph for\n",
    "max_n_logits = 10   # How many logits to attribute from, max. We attribute to min(max_n_logits, n_logits_to_reach_desired_log_prob); see below for the latter\n",
    "desired_logit_prob = 0.95  # Attribution will attribute from the minimum number of logits needed to reach this probability mass (or max_n_logits, whichever is lower)\n",
    "max_feature_nodes = 8192  # Only attribute from this number of feature nodes, max. Lower is faster, but you will lose more of the graph. None means no limit.\n",
    "batch_size=256  # Batch size when attributing\n",
    "verbose = True  # Whether to display a tqdm progress bar and timing report\n",
    "\n",
    "graph = attribute(\n",
    "    prompt=prompt,\n",
    "    model=model,\n",
    "    max_n_logits=max_n_logits,\n",
    "    desired_logit_prob=desired_logit_prob,\n",
    "    batch_size=batch_size,\n",
    "    max_feature_nodes=max_feature_nodes,\n",
    "    offload=None,\n",
    "    verbose=verbose\n",
    ")\n",
    "\n",
    "graph.to_pt(graph_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15e01ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12392, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.active_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aac81c6",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4e057db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruning graph\n"
     ]
    }
   ],
   "source": [
    "slug = \"dallas-austin\"  # this is the name that you assign to the graph\n",
    "graph_file_dir = './graph_files'  # where to write the graph files. no need to make this one; create_graph_files does that for you\n",
    "node_threshold=0.4  # keep only the minimum # of nodes whose cumulative influence is >= 0.8\n",
    "edge_threshold=0.8  # keep only the minimum # of edges whose cumulative influence is >= 0.98\n",
    "\n",
    "# pruning step\n",
    "create_graph_files(\n",
    "    graph_or_path=graph_path,  # the graph to create files for\n",
    "    slug=slug,\n",
    "    output_path=graph_file_dir,\n",
    "    node_threshold=node_threshold,\n",
    "    edge_threshold=edge_threshold\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac413f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the IFrame below, or open your graph here: f'http://localhost:8194/index.html'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"http://localhost:8194/index.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x14b83ed56490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from circuit_tracer.frontend.local_server import serve\n",
    "\n",
    "port = 8194\n",
    "server = serve(data_dir='./graph_files/', port=port)\n",
    "\n",
    "from IPython.display import IFrame\n",
    "print(f\"Use the IFrame below, or open your graph here: f'http://localhost:{port}/index.html'\")\n",
    "display(IFrame(src=f'http://localhost:{port}/index.html', width='100%', height='800px'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53158e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766ad8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4da589b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "server.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7df742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e104fae",
   "metadata": {},
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db072bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruning graph\n",
      "Nodes kept: 0.22%\n",
      "Edges kept: 0.00000806%\n",
      "\n",
      "Original graph scores: (0.7420152425765991, 0.9321903586387634)\n",
      "Pruned graph scores:   (1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "from circuit_tracer.graph import compute_graph_scores, compute_graph_scores_masked, prune_graph\n",
    "from circuit_tracer.utils import create_graph_files\n",
    "from circuit_tracer.utils.create_graph_files import load_graph_data\n",
    "\n",
    "graph = load_graph_data(graph_path)\n",
    "\n",
    "node_threshold=0.1\n",
    "edge_threshold=0.8\n",
    "\n",
    "node_mask, edge_mask, cumulative_scores = prune_graph(graph, node_threshold, edge_threshold)\n",
    "\n",
    "# Sparsity stats\n",
    "print(f\"Nodes kept: {node_mask.sum().item() / len(node_mask):.2%}\")\n",
    "print(f\"Edges kept: {edge_mask.sum().item() / edge_mask.numel():.8%}\")\n",
    "\n",
    "# Compare scores: original vs pruned\n",
    "print(f\"\\nOriginal graph scores: {compute_graph_scores(graph)}\")\n",
    "print(f\"Pruned graph scores:   {compute_graph_scores_masked(graph, node_mask, edge_mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e08044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e86f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a27ffbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e515aba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
